{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Training Data for Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook transforms the training data to the format needed in training. It saves the final data to the data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "from datetime import timedelta\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy \n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, DateTime, Float\n",
    "from sqlalchemy import create_engine, MetaData, Table, inspect\n",
    "import psycopg2\n",
    "from sqlalchemy.dialects import postgresql\n",
    "import datetime\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATABASE_URI = ###\n",
    "#engine = create_engine(DATABASE_URI)\n",
    "engine = sqlite3.connect('data/db.db')\n",
    "c = engine.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres: Create Table for Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = MetaData(engine)\n",
    "target_training_enc = Table('target_training_enc', meta,\n",
    "                     # info\n",
    "                 Column('index', Integer, primary_key=True),\n",
    "                 Column('datum_click', DateTime),\n",
    "                 Column('anbieter_artikelnummer', String),\n",
    "                 Column('userid', String),\n",
    "                 Column('clicked_before', postgresql.ARRAY(String)),\n",
    "                     # target\n",
    "                 Column('pick', Float),\n",
    "                     # context\n",
    "                 Column('days_online_std', Float),\n",
    "                 Column('month_enc', Integer),\n",
    "                     # item\n",
    "                 Column('anbietermarktplatz_enc', Integer),\n",
    "                 Column('anbieterid_enc', Integer),\n",
    "                 Column('warengruppe_enc', Integer),\n",
    "                 Column('text_vec', postgresql.ARRAY(Float)),\n",
    "                 Column('preis_std', Float),\n",
    "                 Column('minve_std', Float), \n",
    "                     # user\n",
    "                 Column('usermkt_enc', Integer),\n",
    "                 Column('anbieterid_enc_user', postgresql.ARRAY(Integer)),\n",
    "                 Column('anbietermarktplatz_enc_user', postgresql.ARRAY(Integer)),\n",
    "                 Column('warengruppe_enc_user', postgresql.ARRAY(Integer)),\n",
    "                 Column('text_vec_user', postgresql.ARRAY(Float)),\n",
    "                 Column('preis_std_user', Float),\n",
    "                 Column('minve_std_user', Float))\n",
    "target_training_enc.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = MetaData(engine)\n",
    "item_enc = Table('item_enc', meta, autoload=True)\n",
    "target_training_enc = Table('target_training_enc', meta, autoload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sqlite3: Create Table for Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''CREATE TABLE target_training_enc\n",
    "             ([index] integer PRIMARY KEY, [datum_click] datetime, [anbieter_artikelnummer] text, \n",
    "             [userid] text, [clicked_before] blob, [pick] integer, [days_online_std] real, [month_enc] integer, \n",
    "             [anbietermarktplatz_enc] integer, [anbieterid_enc] integer, [warengruppe_enc] integer, [text_vec] blob, \n",
    "             [preis_std] real, [minve_std] real, [usermkt_enc] integer, [anbieterid_enc_user] blob, \n",
    "             [anbietermarktplatz_enc_user] blob, [warengruppe_enc_user] blob, [text_vec_user] blob, [preis_std_user] real, \n",
    "             [minve_std_user] real, [days_online_log_std] real, [preis_log_std] real, [preis_log_std_user] real, \n",
    "             [minve_log_std] real, [minve_log_std_user] real)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and save scaler for days online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_days_online = StandardScaler()\n",
    "\n",
    "std_days_online.fit( data.days_online.values.reshape(-1,1))\n",
    "pickle.dump(std_days_online, open(\"data/models/preprocessing/scaler_days_online.pkl\", \"wb\"))\n",
    "#transformed_cont = std.transform(transformed_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run in batches and save data to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/training_data/target_train_done.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11264404"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>userID</th>\n",
       "      <th>anbieter_artikelnummer</th>\n",
       "      <th>datum_click</th>\n",
       "      <th>pick</th>\n",
       "      <th>days_online</th>\n",
       "      <th>month</th>\n",
       "      <th>erstRegMarktplatz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7150000</td>\n",
       "      <td>871340</td>\n",
       "      <td>00373548RL-CUT24_2</td>\n",
       "      <td>2018-11-14 12:55:25+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>11</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7150001</td>\n",
       "      <td>879456</td>\n",
       "      <td>0001017612096</td>\n",
       "      <td>2018-11-14 12:55:27+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7150002</td>\n",
       "      <td>1623689</td>\n",
       "      <td>0034309260767</td>\n",
       "      <td>2018-11-14 12:55:28+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>11</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7150003</td>\n",
       "      <td>1625292</td>\n",
       "      <td>00477078EM12</td>\n",
       "      <td>2018-11-14 12:55:30+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11</td>\n",
       "      <td>EU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7150004</td>\n",
       "      <td>1601824</td>\n",
       "      <td>00690052k858BRR</td>\n",
       "      <td>2018-11-14 12:55:32+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index   userID anbieter_artikelnummer               datum_click  pick  \\\n",
       "0  7150000   871340     00373548RL-CUT24_2 2018-11-14 12:55:25+00:00   0.0   \n",
       "1  7150001   879456          0001017612096 2018-11-14 12:55:27+00:00   0.0   \n",
       "2  7150002  1623689          0034309260767 2018-11-14 12:55:28+00:00   1.0   \n",
       "3  7150003  1625292           00477078EM12 2018-11-14 12:55:30+00:00   0.0   \n",
       "4  7150004  1601824        00690052k858BRR 2018-11-14 12:55:32+00:00   1.0   \n",
       "\n",
       "   days_online  month erstRegMarktplatz  \n",
       "0        193.0     11                ES  \n",
       "1        197.0     11                NL  \n",
       "2       2646.0     11                FR  \n",
       "3         54.0     11                EU  \n",
       "4         40.0     11                FR  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4114404"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtions to \n",
    "- encode the data in log\n",
    "- extract the item from db\n",
    "- extract item data to previous clicks from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_log(df):\n",
    "    df1 = pd.DataFrame({\"index\" : df['index'], \n",
    "                        'datum_click' : df.datum_click, \n",
    "                        'anbieter_artikelnummer': df.anbieter_artikelnummer,\n",
    "                       'userID' : df.userID, \n",
    "                      'month_enc' : df.month})\n",
    "    df1['days_online_std'] = std_days_online.transform(df[['days_online']])\n",
    "    #df1['month_enc'] = (label_enc_month.transform(df['month']) + 1).tolist()\n",
    "    df1['userMkt_enc'] = (label_enc_mkt.transform(df.erstRegMarktplatz.fillna(\"EU\").values) + 1 ).tolist() # not doo in real, already in userTable\n",
    "    df1[\"pick\"] = df.pick\n",
    "    return(df1)\n",
    "\n",
    "def get_item_and_user (df):\n",
    "    # item\n",
    "    item =  pd.read_sql(\"SELECT * from item_enc WHERE anbieter_artikelnummer = %s\", engine , params = (df.anbieter_artikelnummer,))\n",
    "    #item = item.fillnan(value = 0)\n",
    "    df_item = pd.merge(df, item, how = 'left', on = 'anbieter_artikelnummer')\n",
    "    df_item = df_item.dropna() # filter all rows without item-embedding\n",
    "    # user data based on last clicks \n",
    "    # usually first need to get the user data (MKT & last clicked from db)\n",
    "    if len(df.clicked_before.values[0]) > 0:\n",
    "        items_clicked = engine.execute(sqlalchemy.select([item_enc]).where(item_enc.c.anbieter_artikelnummer.in_(df.clicked_before.values[0])))\n",
    "        # reformat item data of user\n",
    "        result_clicked = []\n",
    "        for row in items_clicked:\n",
    "            result_clicked.append(row)\n",
    "        user_detail = pd.DataFrame(result_clicked)\n",
    "        if len(user_detail) > 0:\n",
    "            user_detail.columns = items_clicked.keys()\n",
    "            # make list\n",
    "            anbieterID_enc = user_detail.anbieterID_enc.values.tolist()\n",
    "            anbietermarktplatz_enc = user_detail.anbietermarktplatz_enc.values.tolist()\n",
    "            warengruppe_enc = user_detail.warengruppe_enc.values.tolist()\n",
    "            text_vec = np.array((user_detail.text_vec).values.tolist()[-50:]).mean(axis = 0).tolist() ## only use last 50 !\n",
    "            preis_std = np.array((user_detail.preis_std).values.tolist()).mean(axis = 0)\n",
    "            minVE_std = np.array((user_detail.minVE_std).values.tolist()).mean(axis = 0)\n",
    "            user = pd.DataFrame({'userID' : df.userID, \n",
    "                             'anbieterID_enc' : [anbieterID_enc], \n",
    "                             'anbietermarktplatz_enc' : [anbietermarktplatz_enc], \n",
    "                             'warengruppe_enc' : [warengruppe_enc], \n",
    "                             'text_vec' : [text_vec],\n",
    "                             'preis_std' : preis_std, \n",
    "                             'minVE_std' : minVE_std})\n",
    "        else:\n",
    "            user = pd.DataFrame({'userID' : df.userID, \n",
    "                             'anbieterID_enc' : [[]], \n",
    "                             'anbietermarktplatz_enc' : [[]], \n",
    "                             'warengruppe_enc' : [[]], \n",
    "                             'text_vec' : [[0] * 150],\n",
    "                             'preis_std' : 0, \n",
    "                             'minVE_std' : 0})\n",
    "    else:\n",
    "        user = pd.DataFrame({'userID' : df.userID, \n",
    "                         'anbieterID_enc' : [[]], \n",
    "                         'anbietermarktplatz_enc' : [[]], \n",
    "                         'warengruppe_enc' : [[]], \n",
    "                         'text_vec' : [[0] * 150],\n",
    "                         'preis_std' : 0, \n",
    "                         'minVE_std' : 0})\n",
    "        \n",
    "    df_return = pd.merge(df_item, user, how = \"left\", on = \"userID\", suffixes = (\"\", \"_user\"))\n",
    "    return (df_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch processing: Apply funtions to log and save data to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time : \n",
      "2019-11-21 08:15:27\n",
      "End time :  50000\n",
      "2019-11-21 09:29:58\n",
      "End time :  100000\n",
      "2019-11-21 10:45:52\n",
      "End time :  150000\n",
      "2019-11-21 12:02:26\n",
      "End time :  200000\n",
      "2019-11-21 13:17:49\n",
      "End time :  250000\n",
      "2019-11-21 14:34:42\n",
      "End time :  300000\n",
      "2019-11-21 15:51:37\n",
      "End time :  350000\n",
      "2019-11-21 17:08:38\n",
      "End time :  400000\n",
      "2019-11-21 18:22:50\n",
      "End time :  450000\n",
      "2019-11-21 19:38:02\n",
      "End time :  500000\n",
      "2019-11-21 20:52:34\n",
      "End time :  550000\n",
      "2019-11-21 22:09:09\n",
      "End time :  600000\n",
      "2019-11-21 23:24:05\n",
      "End time :  650000\n",
      "2019-11-22 00:40:53\n",
      "End time :  700000\n",
      "2019-11-22 01:56:05\n",
      "End time :  750000\n",
      "2019-11-22 03:12:13\n",
      "End time :  800000\n",
      "2019-11-22 04:26:24\n",
      "End time :  850000\n",
      "2019-11-22 05:42:12\n",
      "End time :  900000\n",
      "2019-11-22 06:57:40\n",
      "End time :  950000\n",
      "2019-11-22 08:13:17\n",
      "End time :  1000000\n",
      "2019-11-22 09:32:01\n",
      "End time :  1050000\n",
      "2019-11-22 10:50:03\n",
      "End time :  1100000\n",
      "2019-11-22 12:07:24\n",
      "End time :  1150000\n",
      "2019-11-22 13:25:48\n",
      "End time :  1200000\n",
      "2019-11-22 14:43:41\n",
      "End time :  1250000\n",
      "2019-11-22 16:01:02\n",
      "End time :  1300000\n",
      "2019-11-22 17:18:42\n",
      "End time :  1350000\n",
      "2019-11-22 18:40:00\n",
      "End time :  1400000\n",
      "2019-11-22 19:54:02\n",
      "End time :  1450000\n",
      "2019-11-22 21:08:06\n",
      "End time :  1500000\n",
      "2019-11-22 22:23:02\n",
      "End time :  1550000\n",
      "2019-11-22 23:37:58\n",
      "End time :  1600000\n",
      "2019-11-23 00:52:03\n",
      "End time :  1650000\n",
      "2019-11-23 02:06:32\n",
      "End time :  1700000\n",
      "2019-11-23 03:22:13\n",
      "End time :  1750000\n",
      "2019-11-23 04:36:24\n",
      "End time :  1800000\n",
      "2019-11-23 05:51:35\n",
      "End time :  1850000\n",
      "2019-11-23 07:07:32\n",
      "End time :  1900000\n",
      "2019-11-23 08:21:32\n",
      "End time :  1950000\n",
      "2019-11-23 09:36:53\n",
      "End time :  2000000\n",
      "2019-11-23 10:51:24\n",
      "End time :  2050000\n",
      "2019-11-23 12:06:18\n",
      "End time :  2100000\n",
      "2019-11-23 13:21:30\n",
      "End time :  2150000\n",
      "2019-11-23 14:36:06\n",
      "End time :  2200000\n",
      "2019-11-23 15:51:37\n",
      "End time :  2250000\n",
      "2019-11-23 17:06:10\n",
      "End time :  2300000\n",
      "2019-11-23 18:20:49\n",
      "End time :  2350000\n",
      "2019-11-23 19:36:23\n",
      "End time :  2400000\n",
      "2019-11-23 20:51:06\n",
      "End time :  2450000\n",
      "2019-11-23 22:06:15\n",
      "End time :  2500000\n",
      "2019-11-23 23:22:16\n",
      "End time :  2550000\n",
      "2019-11-24 00:38:11\n",
      "End time :  2600000\n",
      "2019-11-24 01:52:45\n",
      "End time :  2650000\n",
      "2019-11-24 03:07:30\n",
      "End time :  2700000\n",
      "2019-11-24 04:22:49\n",
      "End time :  2750000\n",
      "2019-11-24 05:38:33\n",
      "End time :  2800000\n",
      "2019-11-24 06:54:05\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print (\"Start time : \")\n",
    "print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "label_enc_mkt = pickle.load( open( \"data/models/preprocessing/label_mkt.pkl\", \"rb\" ) )\n",
    "label_enc_month = pickle.load (open( \"data/models/preprocessing/label_month.pkl\", \"rb\" ) )\n",
    "std_days_online = pickle.load (open( \"data/models/preprocessing/scaler_days_online.pkl\", \"rb\" ) )\n",
    "\n",
    "batches_start = list(range(0, len(data_new), 50000)) # data\n",
    "batches_end = batches_start[1:]\n",
    "batches_end.append(len(data_new)) # data\n",
    "\n",
    "\n",
    "for i,v in zip(batches_start, batches_end):\n",
    "    \n",
    "    # Transform log data\n",
    "    data_tr = transform_log(data_new[i:v]).reset_index(drop = True)\n",
    "    \n",
    "    # Create user_clicks\n",
    "    clicked_before = []\n",
    "    for r in range(len(data_tr)):\n",
    "        clicked = data[(data.userID == data_tr.userID[r]) & (data.datum_click < (data_tr.datum_click[r] - timedelta(1)))]\n",
    "        clicked_before.append(clicked.anbieter_artikelnummer.values.tolist()[-200:])\n",
    "    data_tr['clicked_before'] = clicked_before\n",
    "    \n",
    "    # Get user & item infos \n",
    "    list_df =[]\n",
    "    for n in range(len(data_tr)):\n",
    "        transformed = get_item_and_user(data_tr[n:n+1]) # data_tr\n",
    "        list_df.append(transformed)\n",
    "    final_df = pd.concat(list_df, sort = True)\n",
    "    final_df.to_sql('target_training_enc', engine, index = False, if_exists = 'append')\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"End time : \", v)\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}